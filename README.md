![logo](https://github.com/user-attachments/assets/7737c6dd-6128-4888-959b-11a2ab4276bb)

# David Brown III
![profilepic](https://github.com/user-attachments/assets/8519fcb2-03d0-4fff-a3c4-79e29f935d4d)

# Contact Info: 
Email: <dabrown1@loyola.edu>
Phone: 240-412-5980

***

## About Me 
Hello! I am an experienced Data Analyst and Information Systems Specialist with over 4 years of proven expertise in data-driven decision-making and business intelligence.


With skills in data visualization, statistical analysis, database management, and data storytelling, I can translate complex datasets into actionable insights and achieve strategic improvements in organizational performance. I am proficient at using Python for automation and data creation, SPSS for statistical modeling, Excel for dynamic reporting and data modeling, and Microsoft Access for building relational databases and executing unique queries.


My detail-oriented skill set, commitment to accuracy and continuous learning, and passion for leveraging data to solve real-world problems position me as a valuable asset to any data-focused team. In my spare time, I like to explore and experience new things. 


You can find me here on [\[LinkedIn\]](https://www.linkedin.com/in/david-brown-iii-171273266/).

***

## Education 
I did my undergraduate at Loyola University Maryland where I earned a Bachelor of Business Administration (BBA) with a concentration in Information Systems and Data Analytics.

***

## Projects

### Python Personality Test Project
This Python project is an interactive personality test built using conditional logic, loops, and score tracking. Created through JDoodle, it helps users discover their personality type based on their quiz responses and score system!!

![PythonData](https://github.com/user-attachments/assets/6069a781-82cd-4d92-9558-c8248449e00a)
![PythonFinishedCode](https://github.com/user-attachments/assets/edd41c26-3b93-4ce5-a3c7-d170cb1ffbfc)
#### Initial Project Idea:
The inspiration for the concept of this project came from a need to display our creative coding skills in Python by working to create an interactive personality quiz. The challenge involved creating a 10-question quiz and each question having a unique point value assigned to its possible answers. Designing a personality test was inspired by the fact that it could give users a simple, fast, and enjoyable means of discovering the type of personality they might have or learning about aspects of personality not always visible. The project was a creative solution to working with Python concepts and developing something that interacts with users in a fun and interesting way.

#### Tools I Used:
The major tools utilized in the implementation of the project were JDoodle, through which the Python code was executed and validated. W3Schools was also used to learn Python syntax and best practices. Course lectures and a chatbot (ChatGPT) were also used to double-check my logic and shed light on the issues with the while loops used in my code.

#### Challenges I Faced:
A key problem that was faced was the task of ensuring that the total score of the quiz accurately reflected the relevant personality type, in such a manner that the scores did not produce results that were too high, not high enough, or random. A lot of experimenting with different score intervals was required to figure out the right distribution of the score intervals so that each interval represented a different personality type. Overcoming this problem helped achieve a better understanding of conditional statements and score calculations in the Python programming language.

#### Other Materials:
Aside from using the internet resources like W3Schools and ChatGPT, I used the course resources to inform my project development. Although I didn't work directly with my fellow students, I used the combined examples and feedback received in the course to refine my methodological framework. 

#### Result:
The major objective of the project was to create a personality evaluation program that could interactively and efficiently compute results from user input. To accomplish that objective, the project successfully developed a fully functional program that interacts with users, calculates total scores, and then presents the user's personality classification. If the chance arises to continue working on the project, I will make it more comprehensive by including more personality classifications, increasing the questionnaire's length and depth, and possibly using graphical interfaces or color-coded outcomes to enhance its applications and interactivity.

 
***

### SPSS Cricket Chirp Analysis Project
This SPSS project provided an in-depth analysis of the relation between temperature and cricket chirping rates using descriptive statistics alongside scatterplot visualization methods. From the findings, there is a strong positive correlation that is clearly evident, showing that with rising temperatures, the rates at which crickets chirp also tend to increase noticeably.

![SPSSDataOverview](https://github.com/user-attachments/assets/53daa619-055e-4563-87af-6877294e3e82)
 ![SPSSContent](https://github.com/user-attachments/assets/71b8c312-9527-4771-adac-d4c15a987f1f)
 #### Initial Project Idea:
This project was undertaken as part of my Computer Science module, Making Sense of Data, where we were tasked with creating visual displays using SPSS. The overall aim was to explore the relationship between temperature and the frequency of cricket chirping. The problem we sought to solve was understanding the degree to which environmental factors, like temperature, influence the behavior of animals, in this case, the frequency of cricket chirping. This kind of analysis is important in that it demonstrates how trends in data explain real-world observable phenomena.

#### Tools I Used:
The major tools used to achieve this project were SPSS software, along with class lectures, teaching videos, and personal notes taken throughout the course regarding the correct use of SPSS.

#### Challenges I Faced:
A major difficulty faced was understanding the right methodologies in SPSS for producing descriptive statistics that included the calculation of the mean, standard deviation, max, and min values for the temperature and chirp datasets. The task of analyzing statistical measures and determining significant correlations by using the visual display offered by the scatterplot presented a big hurdle, one that I overcame through repetitive practice and extensive review of course materials.

#### Other Resources:
Besides the material used in the course, I used no external resources and no direct collaboration with others for the project. I used SPSS tutorials and support documentation on the web to further understand the software capabilities.

#### Result:
The main goal of this research was to illustrate the strong relationship between ambient temperature and the frequency of cricket chirps using accurate data visualization and statistical analysis. This was successfully achieved by creating a scatterplot that showed a clear positive relationship, also supported by descriptive statistics. If the project were to be extended, I would explore additional variables like diurnal cycles or humidity levels to determine if they have any impacts on chirping frequencies, and could also include trendline equations or predictive models to enable a broader analysis.

 
***

### Microsoft Access Retail Database Project
In this project, I used Microsoft Access as a tool to carefully create an extensive retail dataset and then develop a set of meaningful queries. Through this experience, my comprehension of key concepts pertaining to the management of databases, the complex process of creating queries, and the numerous ways in which one can successfully extract useful business information from available data greatly improved.

![AccessDataset](https://github.com/user-attachments/assets/32752a0b-cfd4-4976-aed1-31fe61767f25)
 ![MSAccessContent](https://github.com/user-attachments/assets/0d663842-10a5-4202-9181-23fb7c2eb55d)
 #### Initial Project Idea:
My goal was to utilize Microsoft Access and learn database management and design. My objective was to create my own data set and create significant queries that could uncover interesting interactions between customers and products in a retail shop. I sought to solve the problem of understanding the best ways to handle data and apply queries to answer such relevant business queries like costly products, newest products, or most reordered products.

#### Tools I Used:
My major resources were classroom lectures and videos, and also an AI assistant named ChatGPT who helped in debugging and the rectification of the errors that I encountered in writing and in implementing my queries.

#### Challenges I Faced:
One of the difficulties I experienced was actually attempting to discern how to ask helpful questions that not only functioned but also displayed the data appropriately and in its entirety to its best potential. Learning how to develop appropriate criteria and properly join tables was a learning experience, but one that I was able to navigate by doing and also through instruction in course material.

#### Other Resources:
Aside from the class textbook and the AI assistant, I did not have any direct work with classmates. I did utilize Microsoft Access help files and tutorial sites' samples to learn more about query construction. 

#### Result:
The goal of the project was to efficiently create and maintain my own dataset and create useful queries such as ItemsOver50Bucks, ItemsAddedAfterFeb2025, and HighestReorderLevel. I achieved it and appreciated the ability of databases to extract useful knowledge. If I were to extend it, I would add item and customer purchase connections to better observe sales patterns, reordering patterns, or customer interests.

***
### RStudio NFL 2024 Size Mismatches Project 
This project investigates the impact of pre-snap mismatches on offensive performance in the NFL using player tracking data from the 2022–2023 season. Specifically, we focused on three mismatch types: speed, size, and positional matchups (e.g., wide receiver vs linebacker). By analyzing these mismatches and calculating the average Expected Points Added (EPA) for each scenario, our goal was to determine which mismatch yields the greatest offensive advantage. Using R for data processing and Tableau for visualization, we provide evidence-backed insights into how strategic mismatches can be leveraged to optimize play outcomes.

![IMG_2157](https://github.com/user-attachments/assets/9d8ed293-d971-4e09-a903-74d4094fbe19)
![IMG_2156](https://github.com/user-attachments/assets/00e1e524-c353-48e8-a8c2-43c059a40a24)
![IMG_2155](https://github.com/user-attachments/assets/c67044dc-0d68-4de5-a3e7-b15394da996b)

#### Initial Project Idea:
Our project explores how different types of mismatches (speed, size, and positional) impact offensive success in the NFL. We aim to identify which mismatch types contribute the most to expected points added (EPA) by using player tracking data. The specific focus of this segment is on Size Mismatches, analyzing height and weight differences between offensive and defensive players at the moment of the snap and how those differences affect play outcomes.

#### Tools I Used:
NFL Big Data Bowl Tracking Data (2022–23)
RStudio with packages such as:
- tidyverse (data manipulation and visualization)
- nflreadr (data loading)
- ggplot2 (for visual plots)

#### Challenges I Faced:

- Complex Data Integration Across Multiple Datasets:
One of the main challenges was combining different NFL datasets—specifically the tracking data, play-by-play data, and player metadata. These datasets each use different keys and formats (e.g., nflId, playId, gameId), which required careful joins and filtering. Mismatched or missing identifiers sometimes caused issues in aligning players to plays and matching them across data sources.
- Defining “Size Mismatch” in a Meaningful, Data-Driven Way:
Establishing a clear, statistical definition for a size mismatch was not straightforward. We had to test various height and weight differential thresholds (e.g., 2+ inches or 15+ lbs) to determine what truly constituted a mismatch with a measurable impact on play outcomes. We also debated whether to evaluate these mismatches on absolute differences or positional norms.
- Missing or Noisy Tracking Data:
Not every play in the tracking dataset was usable—some were missing data points or had inconsistencies in player movement. In some plays, players were not captured at the exact frame we needed (like the moment of the snap), or defenders were not clearly assigned. This added extra cleaning steps and affected the accuracy of player matchup assignments.
Identifying Primary Defenders for Each Matchup:
- Determining who the primary defender was for each offensive player (especially wide receivers) was one of the most time-consuming aspects. The dataset does not explicitly provide coverage matchups on every play, so we had to infer matchups based on proximity in the tracking data or use derived variables like pff_primaryDefensiveCoverageMatchupNflId. Even then, coverage assignments sometimes varied mid-play or were ambiguous, especially in zone coverages.

#### Other Resources:
NFL Big Data Bowl starter notebooks and Kaggle forums
Consulted with teammate Evan Alander for pair programming and idea refinement
Referenced prior winning submissions and academic papers on football analytics to fine-tune EPA interpretations and visual storytelling strategies.

***
### NBA Data Analysis Project
This in-depth project explores important trends and insightful information on NBA performance over the period of almost two decades, from 2003 to 2022, based on a rich set of historical data. Through the use of R programming combined with cutting-edge data visualization methods, we managed to identify clear patterns that shed light on a number of aspects such as the impact of individual players, the dominant tendencies of teams, and the general development of game strategy across the league. The main goal of this project was to derive meaningful conclusions through visual storytelling, ultimately helping to place in context the dramatic changes and shifts that have occurred in the sport over the past two decades.

![NBA R Visualizations jpg](https://github.com/user-attachments/assets/478ced5d-c707-42e5-8fa2-d1318f5fc07b)
![NBA R Visualization 2 jpg ](https://github.com/user-attachments/assets/3082c93e-535e-4346-9b9a-eb607e7895a3)
![NBA R Visualization 3 jpg](https://github.com/user-attachments/assets/fa3ae8a9-dbd5-4b9f-bf28-c80d2ad8c82f)
![NBA R Visualization 4 jpg](https://github.com/user-attachments/assets/352a14bc-76b5-4680-8380-62a0deda31c7)

#### Initial Project Idea
The project aimed to answer five key basketball questions by leveraging advanced data visualization and analytical techniques:

- Underrated Scorers: Who had high-scoring seasons without earning MVP recognition?
- Home-Court Advantage Trends: Has playing at home become less of an advantage over time?
- Defensive Impact Players: Which players contributed heavily on defense without being stars?
- Close Game Performance: Which teams won the most games decided by 5 points or fewer?
- Three-Point Evolution: How has the NBA’s reliance on the 3-point shot changed since 2003?

Each section focused on generating unique insights using R and ggplot2, emphasizing clarity, impact, and interpretability.

#### Tools I Used:

RStudio with:
- ggplot2, dplyr, scales, tidyverse

NBA Dataset (2003–2022) including:
- Game details
- Team stats
- Player-level data

- R Markdown for integrating code, analysis, and visuals
- Custom color palettes and labels for improved clarity

#### Challenges I Faced:

- Data Wrangling & Cleaning
The raw data needed to undergo extensive preprocessing—team and game grouping, filtering of seasons, and table reshaping to enable valid summaries to be constructed. Minor inconsistencies across seasons were manually confirmed.

- Combining datasets
Combining game logs, team information, and player performance data took careful effort to join on common keys (e.g., team codes, season IDs), and some datasets were not aligned to begin with.

- Selecting meaningful visualizations
For each question, I had to take time to consider how to represent the insight most well (e.g., line graph vs. bar graph). Some of the graphs took some tinkering with coloring schemes, orientation (flipping coordinates around), and labeling to get it just right.

Balancing Simplicity with Insight
I aimed to ensure the visualizations would still be accessible to everyday fans but retain some level of analytical value. It was difficult to find a balance—remaining understandable without simplistically reducing the data.

#### Other Resources:
- Class tutorials and lecture notes
- ggplot2 documentation and examples
- Peer review and informal feedback from classmates
- Online forums like Stack Overflow for debugging code issues
- Sports media sites (e.g., Basketball Reference) to validate findings

***
#### NCAA 2025 Basketball Season Tableau Project 
