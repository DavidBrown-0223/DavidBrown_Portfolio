![logo](https://github.com/user-attachments/assets/7737c6dd-6128-4888-959b-11a2ab4276bb)

# David Brown III
![profilepic](https://github.com/user-attachments/assets/8519fcb2-03d0-4fff-a3c4-79e29f935d4d)

# Contact Info: 
Email: <dabrown1@loyola.edu>
Phone: 240-412-5980

***

## About Me 
Hello! I am an experienced Data Analyst and Information Systems Specialist with over 4 years of proven expertise in data-driven decision-making and business intelligence.


With skills in data visualization, statistical analysis, database management, and data storytelling, I can translate complex datasets into actionable insights and achieve strategic improvements in organizational performance. I am proficient at using Python for automation and data creation, SPSS for statistical modeling, Excel for dynamic reporting and data modeling, and Microsoft Access for building relational databases and executing unique queries.


My detail-oriented skill set, commitment to accuracy and continuous learning, and passion for leveraging data to solve real-world problems position me as a valuable asset to any data-focused team. In my spare time, I like to explore and experience new things. 


You can find me here on [\[LinkedIn\]](https://www.linkedin.com/in/david-brown-iii-171273266/).

***

## Education 
I did my undergraduate at Loyola University Maryland where I earned a Bachelor of Business Administration (BBA) with a concentration in Information Systems and Data Analytics.

***

## Projects

### Python Personality Test Project
This Python project is an interactive personality test built using conditional logic, loops, and score tracking. Created through JDoodle, it helps users discover their personality type based on their quiz responses and score system!!

![PythonData](https://github.com/user-attachments/assets/6069a781-82cd-4d92-9558-c8248449e00a)
![PythonFinishedCode](https://github.com/user-attachments/assets/edd41c26-3b93-4ce5-a3c7-d170cb1ffbfc)
#### Initial Project Idea:
The inspiration for the concept of this project came from a need to display our creative coding skills in Python by working to create an interactive personality quiz. The challenge involved creating a 10-question quiz and each question having a unique point value assigned to its possible answers. Designing a personality test was inspired by the fact that it could give users a simple, fast, and enjoyable means of discovering the type of personality they might have or learning about aspects of personality not always visible. The project was a creative solution to working with Python concepts and developing something that interacts with users in a fun and interesting way.

#### Tools I Used:
The major tools utilized in the implementation of the project were JDoodle, through which the Python code was executed and validated. W3Schools was also used to learn Python syntax and best practices. Course lectures and a chatbot (ChatGPT) were also used to double-check my logic and shed light on the issues with the while loops used in my code.

#### Challenges I Faced:
A key problem that was faced was the task of ensuring that the total score of the quiz accurately reflected the relevant personality type, in such a manner that the scores did not produce results that were too high, not high enough, or random. A lot of experimenting with different score intervals was required to figure out the right distribution of the score intervals so that each interval represented a different personality type. Overcoming this problem helped achieve a better understanding of conditional statements and score calculations in the Python programming language.

#### Other Materials:
Aside from using the internet resources like W3Schools and ChatGPT, I used the course resources to inform my project development. Although I didn't work directly with my fellow students, I used the combined examples and feedback received in the course to refine my methodological framework. 

#### Result:
The major objective of the project was to create a personality evaluation program that could interactively and efficiently compute results from user input. To accomplish that objective, the project successfully developed a fully functional program that interacts with users, calculates total scores, and then presents the user's personality classification. If the chance arises to continue working on the project, I will make it more comprehensive by including more personality classifications, increasing the questionnaire's length and depth, and possibly using graphical interfaces or color-coded outcomes to enhance its applications and interactivity.

 
***

### SPSS Cricket Chirp Analysis Project
This SPSS project provided an in-depth analysis of the relation between temperature and cricket chirping rates using descriptive statistics alongside scatterplot visualization methods. From the findings, there is a strong positive correlation that is clearly evident, showing that with rising temperatures, the rates at which crickets chirp also tend to increase noticeably.

![SPSSDataOverview](https://github.com/user-attachments/assets/53daa619-055e-4563-87af-6877294e3e82)
 ![SPSSContent](https://github.com/user-attachments/assets/71b8c312-9527-4771-adac-d4c15a987f1f)
 #### Initial Project Idea:
This project was undertaken as part of my Computer Science module, Making Sense of Data, where we were tasked with creating visual displays using SPSS. The overall aim was to explore the relationship between temperature and the frequency of cricket chirping. The problem we sought to solve was understanding the degree to which environmental factors, like temperature, influence the behavior of animals, in this case, the frequency of cricket chirping. This kind of analysis is important in that it demonstrates how trends in data explain real-world observable phenomena.

#### Tools I Used:
The major tools used to achieve this project were SPSS software, along with class lectures, teaching videos, and personal notes taken throughout the course regarding the correct use of SPSS.

#### Challenges I Faced:
A major difficulty faced was understanding the right methodologies in SPSS for producing descriptive statistics that included the calculation of the mean, standard deviation, max, and min values for the temperature and chirp datasets. The task of analyzing statistical measures and determining significant correlations by using the visual display offered by the scatterplot presented a big hurdle, one that I overcame through repetitive practice and extensive review of course materials.

#### Other Resources:
Besides the material used in the course, I used no external resources and no direct collaboration with others for the project. I used SPSS tutorials and support documentation on the web to further understand the software capabilities.

#### Result:
The main goal of this research was to illustrate the strong relationship between ambient temperature and the frequency of cricket chirps using accurate data visualization and statistical analysis. This was successfully achieved by creating a scatterplot that showed a clear positive relationship, also supported by descriptive statistics. If the project were to be extended, I would explore additional variables like diurnal cycles or humidity levels to determine if they have any impacts on chirping frequencies, and could also include trendline equations or predictive models to enable a broader analysis.

 
***

### Microsoft Access Retail Database Project
In this project, I used Microsoft Access as a tool to carefully create an extensive retail dataset and then develop a set of meaningful queries. Through this experience, my comprehension of key concepts pertaining to the management of databases, the complex process of creating queries, and the numerous ways in which one can successfully extract useful business information from available data greatly improved.

![AccessDataset](https://github.com/user-attachments/assets/32752a0b-cfd4-4976-aed1-31fe61767f25)
 ![MSAccessContent](https://github.com/user-attachments/assets/0d663842-10a5-4202-9181-23fb7c2eb55d)
 #### Initial Project Idea:
My goal was to utilize Microsoft Access and learn database management and design. My objective was to create my own data set and create significant queries that could uncover interesting interactions between customers and products in a retail shop. I sought to solve the problem of understanding the best ways to handle data and apply queries to answer such relevant business queries like costly products, newest products, or most reordered products.

#### Tools I Used:
My major resources were classroom lectures and videos, and also an AI assistant named ChatGPT who helped in debugging and the rectification of the errors that I encountered in writing and in implementing my queries.

#### Challenges I Faced:
One of the difficulties I experienced was actually attempting to discern how to ask helpful questions that not only functioned but also displayed the data appropriately and in its entirety to its best potential. Learning how to develop appropriate criteria and properly join tables was a learning experience, but one that I was able to navigate by doing and also through instruction in course material.

#### Other Resources:
Aside from the class textbook and the AI assistant, I did not have any direct work with classmates. I did utilize Microsoft Access help files and tutorial sites' samples to learn more about query construction. 

#### Result:
The goal of the project was to efficiently create and maintain my own dataset and create useful queries such as ItemsOver50Bucks, ItemsAddedAfterFeb2025, and HighestReorderLevel. I achieved it and appreciated the ability of databases to extract useful knowledge. If I were to extend it, I would add item and customer purchase connections to better observe sales patterns, reordering patterns, or customer interests.

***
### NBA Data Analysis Project
This in-depth project explores important trends and insightful information on NBA performance over the period of almost two decades, from 2003 to 2022, based on a rich set of historical data. Through the use of R programming combined with cutting-edge data visualization methods, we managed to identify clear patterns that shed light on a number of aspects such as the impact of individual players, the dominant tendencies of teams, and the general development of game strategy across the league. The main goal of this project was to derive meaningful conclusions through visual storytelling, ultimately helping to place in context the dramatic changes and shifts that have occurred in the sport over the past two decades.

![NBA R Visualizations jpg](https://github.com/user-attachments/assets/478ced5d-c707-42e5-8fa2-d1318f5fc07b)
![NBA R Visualization 2 jpg ](https://github.com/user-attachments/assets/3082c93e-535e-4346-9b9a-eb607e7895a3)
![NBA R Visualization 3 jpg](https://github.com/user-attachments/assets/fa3ae8a9-dbd5-4b9f-bf28-c80d2ad8c82f)
![NBA R Visualization 4 jpg](https://github.com/user-attachments/assets/352a14bc-76b5-4680-8380-62a0deda31c7)

#### Initial Project Idea
The project aimed to answer five key basketball questions by leveraging advanced data visualization and analytical techniques:

- Underrated Scorers: Who had high-scoring seasons without earning MVP recognition?
- Home-Court Advantage Trends: Has playing at home become less of an advantage over time?
- Defensive Impact Players: Which players contributed heavily on defense without being stars?
- Close Game Performance: Which teams won the most games decided by 5 points or fewer?
- Three-Point Evolution: How has the NBA’s reliance on the 3-point shot changed since 2003?

Each section focused on generating unique insights using R and ggplot2, emphasizing clarity, impact, and interpretability.

#### Tools I Used:

RStudio with:
- ggplot2, dplyr, scales, tidyverse

NBA Dataset (2003–2022) including:
- Game details
- Team stats
- Player-level data

- R Markdown for integrating code, analysis, and visuals
- Custom color palettes and labels for improved clarity

#### Challenges I Faced:

- Data Wrangling & Cleaning
The raw data needed to undergo extensive preprocessing—team and game grouping, filtering of seasons, and table reshaping to enable valid summaries to be constructed. Minor inconsistencies across seasons were manually confirmed.

- Combining datasets
Combining game logs, team information, and player performance data took careful effort to join on common keys (e.g., team codes, season IDs), and some datasets were not aligned to begin with.

- Selecting meaningful visualizations
For each question, I had to take time to consider how to represent the insight most well (e.g., line graph vs. bar graph). Some of the graphs took some tinkering with coloring schemes, orientation (flipping coordinates around), and labeling to get it just right.

Balancing Simplicity with Insight
I aimed to ensure the visualizations would still be accessible to everyday fans but retain some level of analytical value. It was difficult to find a balance—remaining understandable without simplistically reducing the data.

#### Other Resources:
- Class tutorials and lecture notes
- ggplot2 documentation and examples
- Peer review and informal feedback from classmates
- Online forums like Stack Overflow for debugging code issues
- Sports media sites (e.g., Basketball Reference) to validate findings

#### Results:
1. Underrated Scorers Over the Years: Players like Tracy McGrady (2003) and Bradley Beal (2021) posted elite scoring seasons (32.1 and 31.3 PPG respectively) but were overlooked for MVP awards. This suggests that team success and all-around performance often weigh heavier than raw scoring when it comes to MVP voting.
2. Home-Court Advantage Trends: From 2003 to 2022, the home team win rate fluctuated between 53.7% and 61.4%. A sharp decline occurred during the 2020 and 2021 pandemic seasons, dropping below 55% due to the absence of fans and altered playing conditions. Home-court advantage rebounded in 2022 to 58.9%, showing how environmental factors affect performance.
3. Teams with the Most Close-Game Wins: The Boston Celtics led all teams with 292 close-game wins, followed by the Dallas Mavericks (287) and Miami Heat (278). These results reflect strong late-game execution, but may also point to consistently tight contests rather than dominant play styles.
4. Evolution of Three-Point Shooting: The average number of 3-point attempts per game more than doubled from 2003 to 2022, rising from around 15 attempts to over 34. This trend mirrors a league-wide shift toward analytics-driven offense and greater emphasis on perimeter scoring. A plateau in 2020–2022 suggests a potential strategic ceiling has been reached.

***
### 2025 NCAA Basketball Data Visualization Project 
This report analyzes NCAA Division I basketball performance trends using both data science methodology and Tableau visualization. This report seeks to transcend the usual drivers of success in the NCAA Tournament — from tournament seed trends and conference strength to style of play and team efficiency statistics like tempo and turnover ratio — by using calculated measures like Power Score, Tournament Readiness, and Grit Index to deliver actionable insight into team success drivers without dependence on seed or reputation.

![NCAA Tournament 1 jpg](https://github.com/user-attachments/assets/b8119bd3-37c1-4b49-8dee-322852819dfe)
![NCAA 2025 2 jpg ](https://github.com/user-attachments/assets/90567f7e-e5c3-4dcc-a036-9057d57099df)

#### Initial Project Idea: 
The motivation behind this project was to uncover hidden patterns in NCAA basketball outcomes by focusing on:

- The relationship between tournament seeding and number of wins
- Conference-level performance comparisons
- Measuring power rankings through a custom formula
- Understanding efficiency through shot type breakdowns
- Introducing new metrics like the Grit Index, Tempo, and Turnover Rate

I aimed to identify underdog advantages, mid-major success stories, and which metrics best correlate with winning deep in March Madness.

#### Tools I Used:
- Tableau: For dashboard creation and visual storytelling
- Excel/CSV datasets: Tournament results, seedings, win counts, and efficiency stats
Custom Metrics:
- Power Score = (Win % × 0.4) + (AdjO × 0.3) + (AdjD × 0.3)
- Grit Index = Win total × Close Game Win %
- Tournament Readiness Score = (Adjust Offensive Efficiency + Adjust Defensive Efficiency) + (Barthag * 100)

####  Challenges I Faced: 
- Metric Creation and Validation: Creating formulas like Power Score and Grit Index required multiple iterations to ensure they produced meaningful rankings. Balancing weights for offensive and defensive efficiency was especially difficult.
- Data Consistency: Datasets varied in structure (team naming conventions, seed formats), so extensive cleaning and normalization were needed to merge everything accurately.
- Visual Balance in Tableau: With so many charts (bar plots, scatterplots, heatmaps), it was challenging to maintain a readable and aesthetically balanced layout.
Representing Mid-Majors Fairly: Ensuring that teams with fewer tournament appearances (but high success rates) were fairly represented against powerhouse programs.

#### Other Resources: 
- KenPom ratings and efficiency stats
- NCAA official March Madness results and seed data
- Tableau community forums and YouTube dashboard tutorials
- Feedback from professors and classmates during peer reviews

#### Results: 
1. VCU, Drake, and St. John’s ranked highest in Tournament Readiness, showing that mid-major and non-blue-blood programs can be elite when given the chance.
2. Top performing conferences included the Big Ten, SEC, and Big 12 in terms of cumulative Power Score — revealing the depth of talent across these leagues.
3. The Shooting Breakdown Heatmap showed Alabama led in 2P% and maintained strong 3P%, indicating balanced and efficient offensive execution.
4. The Grit Index revealed that high-performing teams weren’t just efficient — they were also strong in close games and resilient in tough matchups.
5. Seeding vs Wins Analysis showed that while higher seeds generally win more, lower-seeded teams like Florida Gulf Coast (15) and Loyola Chicago (11) still make deep runs, proving that seeding isn’t everything.
6. Fast Tempo and High Turnover Rates: Teams like Alabama A&M and Longwood were fast-paced but often struggled with ball control — showing the double-edged sword of aggressive play styles.

